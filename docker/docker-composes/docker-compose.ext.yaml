version: '3.7'
services:
  # llm 服务
  my-llm:
    image: llm:v1
    container_name: my-llm
    ports:
      - "8000:8077"
    volumes:
      - ./logs/llm:/app/logs
      - /data/models:/data/models
    environment:
      CUDA_VISIBLE_DEVICES: 0,1
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail localhost:8077/v1/models | grep -q 'data' || exit 1" ]
      interval: 30s
      retries: 3
      start_period: 10s
      timeout: 3s
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]

  # 重排服务
  my-rerank:
    image: rerank:v1
    container_name: rerank
    ports:
      - "8001:8000"
    volumes:
      - ./logs/rerank:/app/logs
      - /data/models:/data/models
    environment:
      CUDA_VISIBLE_DEVICES: 1
      MODEL_NAME: bge-reranker-base
      MAX_LENGTH: 512
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail localhost:8000/health | grep -q 'ok' || exit 1" ]
      interval: 30s
      retries: 3
      start_period: 10s
      timeout: 3s
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]


  # emdding服务.
  my-embedding:
    image: embedding:v1
    container_name: embedding
    ports:
      - "8002:8000"
    volumes:
      - ./logs/embedding:/app/logs
      - /data/models:/data/models
    environment:
      CUDA_VISIBLE_DEVICES: 1
      MODEL_NAME: m3e-base
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail localhost:8000/health | grep -q 'ok' || exit 1" ]
      interval: 30s
      retries: 3
      start_period: 10s
      timeout: 3s
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]

networks:
  default:
    name: llm-servers