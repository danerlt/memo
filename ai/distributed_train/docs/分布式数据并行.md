# 分布式数据并行

## Bert模型样例

### 单机单卡执行结果

```bash
python bert.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-bgmRmv.png)


总共运行耗时: 559.67秒，acc: 88.1912%。

### 单机多卡执行结果

在 2 张 `A100` GPU卡环境上，测试单机2卡的命令如下：

```bash
torchrun --nproc-per-node 2 bert_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-kX7mWa.png)



总共运行耗时: 324.2秒，速度提高了1.7倍左右。acc: 98.6891%

在 2 张 `V100` GPU卡环境上，测试单机2卡的命令如下：

```bash
NCCL_SOCKET_IFNAME=eno1 torchrun --nproc-per-node 2 bert_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-hnblxa.png)



总共运行耗时: 396.78秒，速度提高了1.4倍左右。



### 多机多卡执行结果

在执行多机多卡训练时，需要将代码和数据同步到各个服务器上，执行下面的命令同步：

```bash
# 同步到V100的服务器上
scp -r /data/workspace/disributed_train root@node2:/data/workspace/
# 同步到T4的服务器上
scp -r /data/workspace/disributed_train root@node3:/data/workspace/
```

以 `node1` 服务器作为主节点，服务器直接通信端口为 `12345` 。

在 2 张 A100 GPU卡，测试多机多卡的命令如下：

注意：如果找不到定义网卡需要手动指定 `NCCL_SOCKET_IFNAME` 环境变量，否则会报错。

```bash
NCCL_SOCKET_IFNAME=bond0 torchrun --nnodes=2 --node-rank=0 --master-addr="node1-ip" --master-port=1234 --nproc-per-node 2 bert_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-bAlglT.png)

总共运行耗时: 777.38秒。


在 2 张 V100 上执行命令，测试多机多卡的命令如下：

```bash
NCCL_SOCKET_IFNAME=eno1 torchrun --nnodes=2 --node-rank=1 --master-addr="node2-ip" --master-port=1234 --nproc-per-node 2 bert_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-IYxRI8.png)

总共运行耗时: 777.85秒。

## MNIST训练样例

### 单卡执行结果

#### 在 A100 环境上执行

```bash
python minist.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-14-xUNCh6.png)

总共运行耗时：170.24秒。

#### 在 V100 环境上执行：

```bash
python minist.py
```

![image-20231220100847648](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231220100847648.png)

总共耗时：182秒



### 单机多卡执行结果

#### A100 * 2

在 134 环境上有两张 A100 GPU卡，测试单机2卡的命令如下：

```bash
torchrun --nproc-per-node 2 mnist_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-20-WrhjcG.png)


总共运行耗时: 103 秒，比单机单卡快了 1.7 倍。

#### V100 * 2

在 2 张 V100 GPU卡，测试单机2卡的命令如下：·

```bash
NCCL_SOCKET_IFNAME=eno1 torchrun --nproc-per-node 2 mnist_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-20-r66VhN.png)

总共运行耗时: 124 秒，比单机单卡快了 1.4 倍。

## 多机多卡执行结果

### 2 * A100 和 3 * T4
以 `node-1` 服务器作为主节点，服务器直接通信端口为 `1234` 。

在 `node-1` 环境上有 2 张 A100 GPU卡，测试多机多卡的命令如下：

注意：如果找不到定义网卡需要手动指定 `NCCL_SOCKET_IFNAME` 环境变量，否则会报错。

```bash
torchrun --nnodes=2 --node-rank=0 --master-addr="node1-ip" --master-port=1234 --nproc-per-node 2 mnist_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-15-4dlqbT.png)


在 `node-3` 环境上有 3 张 T4 上执行命令，测试多机多卡的命令如下：

```bash
torchrun --nnodes=2 --node-rank=1 --master-addr="node1-ip" --master-port=1234 --nproc-per-node 3 mnist_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-15-U0wvSB.png)

总共运行耗时: 48 秒，比单机单卡快了 3.5 倍。

### 2 * A100 和 2 * T4
以 `nod1` 服务器作为主节点，服务器直接通信端口为 `12345` 。

在 `node1` 环境上有 2 张 A100 GPU卡，测试多机多卡的命令如下：

注意：如果找不到定义网卡需要手动指定 `NCCL_SOCKET_IFNAME` 环境变量，否则会报错。

```bash
NCCL_SOCKET_IFNAME=bond0 torchrun --nnodes=2 --node-rank=0 --master-addr="node1-ip" --master-port=12345 --nproc-per-node 2 mnist_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-4lye4d.png)


在 `node3` 环境上有 3 张 T4 ，只使用 2 张 T4，测试多机多卡的命令如下：

```bash
NCCL_SOCKET_IFNAME=bond0 torchrun --nnodes=2 --node-rank=1 --master-addr="node1-ip" --master-port=12345 --nproc-per-node 2 mnist_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-cyqmyM.png)


总共运行耗时: 60 秒，比单机单卡快了 2.8 倍。

### 2 * A00 和 2 * V100

以 `node1` 服务器作为主节点，服务器直接通信端口为 `12345` 。

在 `node1` 环境上有 2 张 A100 GPU卡，测试多机多卡的命令如下：

注意：如果找不到定义网卡需要手动指定 `NCCL_SOCKET_IFNAME` 环境变量，否则会报错。
```bash
NCCL_SOCKET_IFNAME=bond0 torchrun --nnodes=2 --node-rank=0 --master-addr="node1-ip" --master-port=12345 --nproc-per-node 2 mnist_ddp.py 
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-qC6e8I.png)

总共运行耗时: 66 秒，比单机单卡快了 2.5 倍。


在 `node2` 环境上有 2 张 V100 上执行命令，测试多机多卡的命令如下：

```bash
NCCL_SOCKET_IFNAME=eno1 torchrun --nnodes=2 --node-rank=1 --master-addr="node1-ip" --master-port=12345 --nproc-per-node 2 mnist_ddp.py
```

![](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/2023-12-19-Cl7QNl.png)

总共运行耗时: 66 秒，比单机单卡快了 2.5 倍。









## 参考链接

- [pytorch多机多卡分布式训练](https://zhuanlan.zhihu.com/p/464943370)
- [PyTorch分布式训练简明教程](https://blog.csdn.net/xiaohu2022/article/details/105325610)
- [Pytorch DDP分布式训练介绍](https://shomy.top/2022/01/05/torch-ddp-intro/) 

