# 环境搭建

## SSH免密

```
服务器配置：
node1: A100 40G *2
node2: V100S 32G*2
node3: T4 16G *3
```

SSH免密登录的操作步骤如下：

在本地机器上生成SSH密钥对。在命令行中输入下面的命令，然后按回车三次，即可在 `~/.ssh/` 目录下生成 `id_rsa` （私钥）和 `id_rsa.pub`（公钥） 两个文件。

```bash
 ssh-keygen -t rsa
```

![image-20231212154244255](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231212154244255.png)

将公钥手动复制到远程服务器的` ~/.ssh/authorized_keys` 文件中。

测试SSH免密登录。在命令行中输入 

```bash
ssh user@remote
```

如果没有提示输入密码，那么就说明SSH免密登录设置成功了，`user`和`remote`设置成实际的值。

**注意**：

-   **node1需要免密访问node2,需要将node1的公钥放到node2的authorized_keys文件。**
-   `.ssh`目录的权限必须为700，`authorized_keys`文件的权限必须是600

## 安装Nvidia显卡驱动

### 查看系统和显卡信息

#### 查看操作系统信息

```bash
$ uname -m && cat /etc/*release
x86_64
CentOS Linux release 7.9.2009 (Core)
NAME="CentOS Linux"
VERSION="7 (Core)"
ID="centos"
ID_LIKE="rhel fedora"
VERSION_ID="7"
PRETTY_NAME="CentOS Linux 7 (Core)"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:centos:centos:7"
HOME_URL="https://www.centos.org/"
BUG_REPORT_URL="https://bugs.centos.org/"

CENTOS_MANTISBT_PROJECT="CentOS-7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT="centos"
REDHAT_SUPPORT_PRODUCT_VERSION="7"

CentOS Linux release 7.9.2009 (Core)
CentOS Linux release 7.9.2009 (Core)

```

`x86_64` 表示在 64 位系统上运行。下面是 Linux 发行版的信息。

#### 查看内核版本

CUDA 驱动程序要求在安装驱动程序时以及重建驱动程序时安装内核运行版本的内核头文件和开发包。例如，如果您的系统运行内核版本 3.17.4-301，则还必须安装 3.17.4-301 内核头文件和开发包。

```bash
$ uname -r
3.10.0-1160.el7.x86_64
```

#### 查看显卡型号

```bash
$ lspci | grep -i nvidia
3b:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100S PCIe 32GB] (rev a1)
86:00.0 3D controller: NVIDIA Corporation GV100GL [Tesla V100S PCIe 32GB] (rev a1)
```

如果提示 `lspci: command not found`，需要安装`pciutils`工具包

```
yum install pciutils -y
```

如果您没有看到任何设置，在命令行输入 `update-pciids `（通常在 `/sbin` 中找到）来更新 Linux 维护的 PCI 硬件数据库，然后重新运行之前的 `lspci`。

### 下载Nvidia 驱动安装文件

首先在 [https://www.nvidia.cn/Download/index.aspx?lang=cn](https://www.nvidia.cn/Download/index.aspx?lang=cn) 上输入显卡型号、操作系统、CUDA Toolkit版本，然后搜索：

![image-20231206102821613](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206102821613.png)

然后点击下载

![image-20231206102847233](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206102847233.png)

下载链接为： [https://cn.download.nvidia.com/tesla/470.223.02/NVIDIA-Linux-x86_64-470.223.02.run](https://cn.download.nvidia.com/tesla/470.223.02/NVIDIA-Linux-x86_64-470.223.02.run)

### 安装依赖

```bash
yum install -y gcc gcc-c++ kernel-devel-$(uname -r) kernel-headers-$(uname -r)
```

![image-20231212140932040](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231212140932040.png)

### 停止GPU上的任务和卸载旧的驱动

```bash
#准备工作 kill 所有与nvidia 有关的服务
$: su root # 切换到管理员杼下

$: sudo service ligthdm stop

#在安装驱动前，应保证没有相应的CUDA的程序在运行
$: fuser -v /dev/nvidia*
$: kill -9 [PID]

# 卸载旧的驱动
$: /usr/bin/nvidia-uninstall
```

### 禁用 nouveau 驱动

Nouveau 是一个开源的 Nvidia 显卡驱动程序项目，旨在为 Linux 系统提供对 Nvidia 显卡的支持。在安装 Nvidia的驱动之前需要将 Nouveau 的驱动禁用掉。

编辑 `/etc/modprobe.d/blacklist.conf` 文件，添加以下内容：

```text
blacklist nouveau
options nouveau modeset=0
```

使用 dracut重新建立 initramfs nouveau 并且备份 initramfs nouveau image镜像

```bash
mv /boot/initramfs-$(uname -r).img /boot/initramfs-$(uname -r).img.bak
```

重新建立新的 the initramfs file:

```bash
dracut -v /boot/initramfs-$(uname -r).img $(uname -r)
```

![image-20231206140439734](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206140439734.png)

然后重启：

```
sudo reboot
```

重启后，执行：

```
lsmod | grep nouveau
```

如果没有屏幕输出，说明禁用 `nouveau` 成功。

### 安装 Nvidia 驱动

执行下载的驱动安装文件`NVIDIA-Linux-x86_64-470.223.02.run`

```bash
sh NVIDIA-Linux-x86_64-470.223.02.run -no-x-check 
```

安装过程中的提示选择`yes`或者`OK`，具体截图可参考： [CentOS 7安装Nvidia驱动](https://yinguobing.com/install-nvidia-driver-centos-7/)

默认情况下如果 检测到 `X server` 在运行中停止安装，需要设置  `-no-x-check` 参数是当 `X server` 运行中的时候可以继续安装。

### 验证安装结果

使用 `nvidia-smi` 命令验证：

```bash
nvidia-smi
```

![image-20231206141510431](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206141510431.png)


## 安装CUDA Toolkit文档

CUDA Toolkit是由NVIDIA提供的用于GPU计算的软件开发工具包。它包括了一系列用于GPU加速计算的库、编译器、调试器和其他工具，以便开发者能够利用NVIDIA的GPU进行并行计算和高性能计算任务。CUDA Toolkit通常用于加速科学计算、深度学习、机器学习和其他需要大规模并行计算的应用程序。

通过 [https://developer.nvidia.com/cuda-11-4-0-download-archive](https://developer.nvidia.com/cuda-11-4-0-download-archive) 下载对应的安装包，注意要和Nvidia Driver的版本一致。

![image-20231206162705781](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206162705781.png)

下载命令：

```bash
wget https://developer.download.nvidia.com/compute/cuda/11.4.0/local_installers/cuda_11.4.0_470.42.01_linux.run
```

安装命令：

```bash
sudo sh cuda_11.4.0_470.42.01_linux.run
```

接受协议输入`accept`

![image-20231206172606863](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206172606863.png)

在 Driver 选项按空格取消选择，然后使用方向键移动到 `Install`选项回车。

![image-20231206172851336](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206172851336.png)

安装完成输出：

![image-20231206173155341](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231206173155341.png)

设置环境变量，编辑 `/etc/profile`文件，追加下面的内容：

```bash
export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
```


## 安装 conda

Conda是一个开源的软件包管理系统和环境管理系统，用于安装和管理多个软件包及其依赖。它特别适用于数据科学和机器学习领域，因为可以轻松管理不同版本的Python以及不同的数据分析工具和库。Conda允许用户创建、导出、安装和更新环境。conda是Anaconda发行版的一部分，Anaconda是一个流行的Python发行版，专注于数据科学和机器学习。

在 [Anaconda Installing on Linux](https://docs.anaconda.com/free/anaconda/install/linux/) 查看安装包 URL。

![image-20231212145147194](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231212145147194.png)



安装依赖：

```bash
yum install -y libXcomposite libXcursor libXi libXtst libXrandr alsa-lib mesa-libEGL libXdamage mesa-libGL libXScrnSaver 
```

下载安装包：

```bash
curl -o https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh
```

安装 Anaconda：

```bash
bash Anaconda3-2023.09-0-Linux-x86_64.sh
```

按Enter键查看许可协议。然后按住Enter键滚动。

输入yes以同意许可协议。

使用 Enter 接受默认安装位置，使用 CTRL+C 取消安装，或输入另一个文件路径来指定备用安装目录。如果您接受默认安装位置，安装程序将显示 `PREFIX=/home/<USER>/anaconda3` 并继续安装。

输入“yes”，通过运行 `conda init` 来初始化 Anaconda发行版。

关闭并重新打开终端窗口以使安装生效，或输入命令 `source ~/.bashrc` 刷新终端。



## Python开发环境搭建

接下来创建一个 `conda` 环境用来进行开发。

```bash
# 创建一个名字叫dis的环境，指定Python版本为3.10
conda create -n dis python=3.10

# 等待环境创建完成 切换到对应的环境
conda activate dis
```

### 安装Pytorch

`PyTorch`是一个开源的Python机器学习库。

`PyTorch `和 `cuda` 版本对应关系参考链接： [https://docs.nvidia.com/deploy/cuda-compatibility/](https://docs.nvidia.com/deploy/cuda-compatibility/) ，这里使用`cuda 11.7`,  `pytorch 2.0.1`为例

由于服务器无法访问 `PyTorch` 的网站,所以需要下载编译后的安装包安装。

通过[PyTorch Get Started](https://pytorch.org/get-started/previous-versions/)查看对应的版本

![image-20231212151451044](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231212151451044.png)

可以看到 `torch` 为`2.0.1`对应的`torchvision`版本为`0.15.2`，`torchaudio`为`2.0.2`

然后去`index-url`中下载`PyTorch` whl包, 下载地址: [https://download.pytorch.org/whl/cu117](https://download.pytorch.org/whl/cu117)

![image-20231212151810532](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231212151810532.png)

以 `torch`为例，搜索对应的版本，然后选择对应的`cuda`版本，Python版本和操作系统版本。

![image-20231212151922126](https://danerlt-1258802437.cos.ap-chongqing.myqcloud.com/images/image-20231212151922126.png)



安装 `PyTorch`，安装过程中会安装一些依赖库，使用阿里云 pip 源进行加速:

```bash
pip install torch-2.0.1+cu117-cp310-cp310-linux_x86_64.whl -i https://mirrors.aliyun.com/pypi/simple/
pip install torchaudio-2.0.2+cu117-cp310-cp310-linux_x86_64.whl -i https://mirrors.aliyun.com/pypi/simple/
pip install torchvision-0.15.2+cu117-cp310-cp310-linux_x86_64.whl -i https://mirrors.aliyun.com/pypi/simple/
```

验证 `torch` 是否安装成功，`torch.cuda.is_available()`返回 `True` 表示安装成功。:

```python
$ python
Python 3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> import torch
>>> print(torch.__version__)
2.0.1+cu117
>>> torch.cuda.is_available()
True
>>> 
```

如果出现下面错误，说明环境变量有问题

```
ImportError: /miniconda3/envs/dis/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so: symbol cublasSetWorkspace_v2, version libcublas.so.11 not defined in file libcublas.so.11 with link time reference
```

需要将 `~/.bahsrc`文件中的环境变量设置成：

```bash
export PATH=/usr/local/cuda-11.4/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=/usr/local/cuda-11.4/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
```

### 安装`DeepSpeed`

`DeepSpeed`是一个由微软开发的开源深度学习优化库，旨在提高大规模模型训练的效率和可扩展性。它通过多种技术手段来加速训练，包括模型并行化、梯度累积、动态精度缩放、本地模式混合精度等。`DeepSpeed`还提供了一些辅助工具，如分布式训练管理、内存优化和模型压缩等，以帮助开发者更好地管理和优化大规模深度学习训练任务。此外，`DeepsSeed`基于`PyTorch`构建，只需要简单修改即可迁移。

```bash
pip install deepspeed -i https://mirrors.aliyun.com/pypi/simple/
```

验证是否安装成功：

```
ds_report
[2023-12-06 16:24:02,687] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [OKAY]
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
 [WARNING]  async_io requires the dev libaio .so object and headers but these were not found.
 [WARNING]  async_io: please install the libaio-devel package with yum
 [WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [NO] ....... [NO]
fused_adam ............. [NO] ....... [OKAY]
cpu_adam ............... [NO] ....... [OKAY]
cpu_adagrad ............ [NO] ....... [OKAY]
cpu_lion ............... [NO] ....... [OKAY]
 [WARNING]  Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH
evoformer_attn ......... [NO] ....... [NO]
fused_lamb ............. [NO] ....... [OKAY]
fused_lion ............. [NO] ....... [OKAY]
inference_core_ops ..... [NO] ....... [OKAY]
cutlass_ops ............ [NO] ....... [OKAY]
quantizer .............. [NO] ....... [OKAY]
ragged_device_ops ...... [NO] ....... [OKAY]
ragged_ops ............. [NO] ....... [OKAY]
random_ltd ............. [NO] ....... [OKAY]
 [WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.0
 [WARNING]  using untested triton version (2.0.0), only 1.0.0 is known to be compatible
sparse_attn ............ [NO] ....... [NO]
spatial_inference ...... [NO] ....... [OKAY]
transformer ............ [NO] ....... [OKAY]
stochastic_transformer . [NO] ....... [OKAY]
transformer_inference .. [NO] ....... [OKAY]
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/data/user/miniconda3/envs/dis/lib/python3.10/site-packages/torch']
torch version .................... 2.0.1+cu117
deepspeed install path ........... ['/data/user/miniconda3/envs/dis/lib/python3.10/site-packages/deepspeed']
deepspeed info ................... 0.12.4, unknown, unknown
torch cuda version ............... 11.7
torch hip version ................ None
nvcc version ..................... 11.4
deepspeed wheel compiled w. ...... torch 2.0, cuda 11.7
shared memory (/dev/shm) size .... 125.70 GB

```





## 参考链接

-   [英伟达官网安装文档](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)
-   [CentOS 7安装Nvidia驱动](https://yinguobing.com/install-nvidia-driver-centos-7/)
-   [Anaconda Installing on Linux](https://docs.anaconda.com/free/anaconda/install/linux/)

