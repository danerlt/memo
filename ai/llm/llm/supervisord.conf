[supervisord]
nodaemon=true
user=root
loglevel=info
logfile=/app/logs/supervisord.log
environment=CUDA_VISIBLE_DEVICES="0,1"

[program:controller]
command=python3 -m fastchat.serve.controller --host 0.0.0.0 --port 21110
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/app/logs/controller.log
stderr_logfile=/app/logs/controller.log

[program:openai_api]
command=python3 -m fastchat.serve.openai_api_server --host 0.0.0.0 --port 8077 --controller-address http://0.0.0.0:21110
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/app/logs/openai_api.log


[program:qwen]
environment=CUDA_VISIBLE_DEVICES="0,1"
command=python3 -m fastchat.serve.vllm_worker --host 0.0.0.0 --port 21111 --controller-address http://0.0.0.0:21110 --worker-address http://0.0.0.0:21111 --model-path /data/models/Qwen-7B-Chat --model-names Qwen-7B-Chat
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/app/logs/qwen.log
stderr_logfile=/app/logs/qwen.log

[program:chatglm]
environment=CUDA_VISIBLE_DEVICES="0,1"
command=python3 -m fastchat.serve.model_worker --host 0.0.0.0 --port 21112 --controller-address http://0.0.0.0:21110 --worker-address http://0.0.0.0:21112 --model-path /data/models/chatglm3-6b-32k --model-names chatglm3-6b-32k
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/app/logs/chatglm.log
stderr_logfile=/app/logs/chatglm.log

[program:bge]
environment=CUDA_VISIBLE_DEVICES="0,1"
command=python3 -m fastchat.serve.model_worker --host 0.0.0.0 --port 21113 --controller-address http://0.0.0.0:21110 --worker-address http://0.0.0.0:21113 --model-path /data/models/bge-base-zh --model-names bge-base-zh
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/app/logs/bge.log
stderr_logfile=/app/logs/bge.log